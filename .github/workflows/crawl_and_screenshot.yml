name: Website Screenshot and Sitemap

on:
  workflow_dispatch:
    inputs:
      website_url:
        description: 'The URL of the website to crawl'
        required: true
        type: string

jobs:
  crawl_and_screenshot:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          pip install requests beautifulsoup4 selenium webdriver-manager
          # Install Chrome using apt
          wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          sudo sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google.list'
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable

      - name: Crawl and Screenshot
        env:
          WEBSITE_URL: ${{ github.event.inputs.website_url }}
        run: python .github/scripts/crawl_and_screenshot.py

      - name: Commit changes
        run: |
          git config --local user.email "github-actions@github.com"
          git config --local user.name "GitHub Actions"
          git add screenshots/ sitemap.txt
          git commit -m "Add website screenshots and sitemap" || echo "No changes to commit"
          git push origin HEAD:${GITHUB_REF} || echo "No changes to push"
